---
title: ''
output:
  html_document:
    css:
    - style.css
    - https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css
  pdf_document: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE)

```

```{r Data_import_main, echo = FALSE, message = FALSE, warning= FALSE}
rm(list = ls())
library(pacman)
p_load(tidyverse, leaflet, dplyr, readr, reshape2,
       jsonlite, rvest, magrittr, htmltab, knitr)

# Data on Drug accidents in the US 2015-2018
drug_set <- read_csv("https://data.cdc.gov/api/views/xkb8-kh2a/rows.csv?accessType=DOWNLOAD")

# Adding states names to dataset

drug_set <- drug_set %>% mutate(state = case_when(State == "AK" ~ "Alaska",
                                                  State == "AL" ~ "Alabama",
                                                  State == "AZ" ~ "Arizona",
                                                  State == "AR" ~ "Arkansas",
                                                  State == "CA" ~ "California",
                                                  State == "CO" ~ "Colorado",
                                                  State == "CT" ~ "Connecticut",
                                                  State == "DC" ~ "District of Columbia",
                                                  State == "DE" ~ "Delaware",
                                                  State == "FL" ~ "Florida",
                                                  State == "GA" ~ "Georgia",
                                                  State == "HI" ~ "Hawaii",
                                                  State == "ID" ~ "Idaho",
                                                  State == "IL" ~ "Illinois",
                                                  State == "IN" ~ "Indiana",
                                                  State == "IA" ~ "Iowa",
                                                  State == "KS" ~ "Kansas",
                                                  State == "KY" ~ "Kentucky",
                                                  State == "LA" ~ "Louisiana",
                                                  State == "ME" ~ "Maine",
                                                  State == "MD" ~ "Maryland",
                                                  State == "MA" ~ "Massachusetts",
                                                  State == "MI" ~ "Michigan",
                                                  State == "MN" ~ "Minnesota",
                                                  State == "MS" ~ "Mississippi",
                                                  State == "MO" ~ "Missouri",
                                                  State == "MT" ~ "Montana",
                                                  State == "NE" ~ "Nebraska",
                                                  State == "NV" ~ "Nevada",
                                                  State == "NH" ~ "New Hampshire",
                                                  State == "NJ" ~ "New Jersey",
                                                  State == "NM" ~ "New Mexico",
                                                  State == "NY" ~ "New York",
                                                  State == "NC" ~ "North Carolina",
                                                  State == "ND" ~ "North Dakota",
                                                  State == "OH" ~ "Ohio",
                                                  State == "OK" ~ "Oklahoma",
                                                  State == "OR" ~ "Oregon",
                                                  State == "PA" ~ "Pennsylvania",
                                                  State == "RI" ~ "Rhode Island",
                                                  State == "SC" ~ "South Carolina",
                                                  State == "SD" ~ "South Dakota",
                                                  State == "TN" ~ "Tennessee",
                                                  State == "TX" ~ "Texas",
                                                  State == "US" ~ "United States of America federal state",
                                                  State == "UT" ~ "Utah",
                                                  State == "VT" ~ "Vermont",
                                                  State == "VA" ~ "Virginia", 
                                                  State == "WA" ~ "Washington",
                                                  State == "WV" ~ "West Virginia",
                                                  State == "WI" ~ "Wisconsin",
                                                  State == "WY" ~ "Wyoming",
                                                  State == "YC" ~ "Yucatan(MEX)"))
# Changing colnames 
colnames(drug_set) <- c("State","State_abbreviations","Year", "Month", "Indicator", "Deaths", "Predicted_Value", "Percent_complete", "Percent_pending_investigation","Footnote","State_name")

# Removing the first colum we have two of                                                                       
drug_set$State <- NULL

# Rearranging colums 
drug_set <- drug_set[,c(10,1,2,3,4,5,6,7,8,9)]


# Taking a look at the dataset after cleaning. 
# knitr::kable(head(drug_set))

# Examining the footnote colum
# unique(drug_set$Footnote)
# unique(drug_set$Year)


# If the code below is runned the data for 2017 and 2018 are removed. This is because the investigation on cases not are 
# juridicaly finished and solved and some cases are underreported due to incomplete data. We still want to use the data for 2017 and 2018.

# drug_set <- drug_set %>%
  # filter(is.na(Footnote))

##################################

```


```{r Data_import_population}

############################
# We need population data for all the years so we can compare the different states by how many people actualy living in them.
# Without this comparison it would mean nothing that there is more deaths in California than in Wyoming since it lives 
# a lot more people in california compared to Wyoming. 


# population pr state 2015
# we are using the rvest package to scrape the following website with the data for 2015.
page <- read_html("https://www.infoplease.com/us/states/state-population-rank-2015")

# the table are in the node "tr td"
pop2015 <- page%>% html_nodes("tr td") %>% html_text()

# making the node as a one colum dataframe for easier manipulation 
pop2015 <- as.data.frame(pop2015)

# splitting the dataframe into two colums 
pop2015 <- as.data.frame(split(pop2015, 1:2))

# using dplyr to make it a tibble 
pop2015 <- tbl_df(pop2015)

# changing the names of the colums 
names(pop2015)[1] <- "State"
names(pop2015)[2] <- "Population2015"

# Making everything as characters so we can use the function below
pop2015$State <- as.character(pop2015$State)
pop2015$Population2015 <- as.character(pop2015$Population2015)

# taking the "," out of the tibble so we make the population data numeric 
pop2015[] <- lapply(pop2015, function(x) as.character(gsub("[,]", "", x)))

# making the data numeric 
pop2015$Population2015 <- as.numeric(pop2015$Population2015)

# arranging the states alfabeticaly 
pop2015 <- pop2015[order(pop2015$State),]

# removing row 45 containing the sum of all the states 
pop2015 <- pop2015[-45,]

# changing dc to District of Columbia so it will correspond with the other data 
pop2015[8,1] <- "District of Columbia"

# The scrape for 2015 is finished. 


############################

# population pr state 2016 
# For 2016 we are also using the rvest package to scrape the following website with the data for 2016.
page <- read_html("https://dilemma-x.net/2016/12/21/u-s-state-populations-2016-most-populous-states/")

# the table are in the node "tr td"
pop2016 <- page%>% html_nodes("tr td") %>% html_text()

# same prosidure as for 2015
pop2016 <- as.data.frame(pop2016)
pop2016 <- tbl_df(pop2016)

# removing all the data for the rows not containing the table we want, could to this just collecting the rows as well.
pop2016 <- pop2016[-c(1:364),]
pop2016 <- pop2016[-c(172:213),]

# same prosidure as for 2015
pop2016 <- as.data.frame(split(pop2016, 1:3))
pop2016 <- tbl_df(pop2016)

# removing a colum for 2010 data 
pop2016$pop2016.1 <- NULL

# renaming colums 
names(pop2016)[1] <- "State"
names(pop2016)[2] <- "Population2016"

# removing summary rows of data
pop2016 <- pop2016[-c(1:6),]

# making everything as characters so we can use the function below 
pop2016$State <- as.character(pop2016$State)
pop2016$Population2016 <- as.character(pop2016$Population2016)

# removing "," from the data so could make numeric 
pop2016[] <- lapply(pop2016, function(x) as.character(gsub("[,]", "", x)))

# making numeric
pop2016$Population2016 <- as.numeric(pop2016$Population2016)

# arranging the states alfabeticaly 
pop2016 <- pop2016[order(pop2016$State),]

# Populationdata for 2016 is ready 

############################

# Population pr state 2017 
# This is a wikipedia table so it is really nice to scrape using the htmlTab package 
pop2017 <- htmltab("https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States_by_population",3)

# already a table, so just removing the colums we dont need 
pop2017 <- pop2017[,c(1,3)]

# making it a tibble 
pop2017 <- tbl_df(pop2017)

# removing the rows containing summarys and other variables not relevant 
pop2017 <- pop2017[-c(7,13,14,22,27,32,33,39,47,48,57,63,64,65,66,67,68,69,70,71),]

# we now have 51 states, and renaming the colums 
names(pop2017)[1] <- "State"
names(pop2017)[2] <- "Population2017"

# Just doing the same as for the previous years 
pop2017$State <- as.character(pop2017$State)
pop2017$Population2017 <- as.character(pop2017$Population2017)
pop2017[] <- lapply(pop2017, function(x) as.character(gsub("[,]", "", x)))
pop2017$Population2017 <- as.numeric(pop2017$Population2017)
pop2017 <- pop2017[order(pop2017$State),]

# 2017 is now ready for take off.

############################

# for 2018 we are back with the rvest package and "tr td" so this should be a quick one.
page <- read_html("http://worldpopulationreview.com/states/")
pop2018 <- page%>% html_nodes("tr td") %>% html_text()
pop2018 <- as.data.frame(pop2018)
pop2018 <- as.data.frame(split(pop2018, 1:5))
pop2018 <- tbl_df(pop2018)
pop2018 <- pop2018[,c(2,3)]
names(pop2018)[1] <- "State"
names(pop2018)[2] <- "Population2018"
pop2018 <- pop2018[-1,]
pop2018$State <- as.character(pop2018$State)
pop2018$Population2018 <- as.character(pop2018$Population2018)
pop2018[] <- lapply(pop2018, function(x) as.character(gsub("[,]", "", x)))
pop2018$Population2018 <- as.numeric(pop2018$Population2018)
pop2018 <- pop2018[order(pop2018$State),]

# Boom, 2018 is go, then we just merge all the datasets togheter with the merge function.
PopulationUS <- Reduce(function(x, y) merge(x, y, all=TRUE), list(pop2015,pop2016,pop2017,pop2018))
# This is actually so cool hehe. 
```




```{r Data_import_unemployment}
# it is also interesting to see if we can see some correlation with drug overdoses and unemployment rates for the different states, so we should scrape some data on that as well. BTW, we are using the CSS selector gadget plugin for Google chrome to
# see what nodes we should collect from the different webpages. 

# for 2015 
page <- read_html("https://www.bls.gov/lau/lastrk15.htm")
states2015 <- page%>% html_nodes("tr th") %>% html_text()
states2015 <- as.data.frame(states2015)
states2015 <- tbl_df(states2015)
states2015 <- states2015[c(5:55),]
names(states2015)[1] <- "State"
states2015$State <- as.character(states2015$State)


figures2015 <- page%>% html_nodes("td span") %>% html_text()
figures2015 <- as.data.frame(figures2015)
figures2015 <- tbl_df(figures2015)

figures2015 <- figures2015[c(4:105),]
figures2015 <- as.data.frame(split(figures2015, 1:2))
figures2015 <- tbl_df(figures2015)
names(figures2015)[1] <- "Rate2015"
names(figures2015)[2] <- "Rank2015"
figures2015$Rate2015 <- as.character(figures2015$Rate2015)
figures2015$Rank2015 <- as.character(figures2015$Rank2015)
figures2015$Rate2015 <- as.numeric(figures2015$Rate2015)
figures2015$Rank2015 <- as.numeric(figures2015$Rank2015)

unploy2015 <- cbind(states2015,figures2015) 
unploy2015 <- unploy2015[order(unploy2015$State),]


# Same structure on data for the other years so just doing the same but changing the numbers to 201x
# for 2016
page <- read_html("https://www.bls.gov/lau/lastrk16.htm")
states2016 <- page%>% html_nodes("tr th") %>% html_text()
states2016 <- as.data.frame(states2016)
states2016 <- tbl_df(states2016)
states2016 <- states2016[c(5:55),]
names(states2016)[1] <- "State"
states2016$State <- as.character(states2016$State)

figures2016 <- page%>% html_nodes("td span") %>% html_text()
figures2016 <- as.data.frame(figures2016)
figures2016 <- tbl_df(figures2016)

figures2016 <- figures2016[c(4:105),]
figures2016 <- as.data.frame(split(figures2016, 1:2))
figures2016 <- tbl_df(figures2016)
names(figures2016)[1] <- "Rate2016"
names(figures2016)[2] <- "Rank2016"
figures2016$Rate2016 <- as.character(figures2016$Rate2016)
figures2016$Rank2016 <- as.character(figures2016$Rank2016)
figures2016$Rate2016 <- as.numeric(figures2016$Rate2016)
figures2016$Rank2016 <- as.numeric(figures2016$Rank2016)

unploy2016 <- cbind(states2016,figures2016) 
unploy2016 <- unploy2016[order(unploy2016$State),]

# for 2017
page <- read_html("https://www.bls.gov/lau/lastrk17.htm")
states2017 <- page%>% html_nodes("tr th") %>% html_text()
states2017 <- as.data.frame(states2017)
states2017 <- tbl_df(states2017)
states2017 <- states2017[c(5:55),]
names(states2017)[1] <- "State"
states2017$State <- as.character(states2017$State)


figures2017 <- page%>% html_nodes("td span") %>% html_text()
figures2017 <- as.data.frame(figures2017)
figures2017 <- tbl_df(figures2017)

figures2017 <- figures2017[c(4:105),]
figures2017 <- as.data.frame(split(figures2017, 1:2))
figures2017 <- tbl_df(figures2017)
names(figures2017)[1] <- "Rate2017"
names(figures2017)[2] <- "Rank2017"
figures2017$Rate2017 <- as.character(figures2017$Rate2017)
figures2017$Rank2017 <- as.character(figures2017$Rank2017)
figures2017$Rate2017 <- as.numeric(figures2017$Rate2017)
figures2017$Rank2017 <- as.numeric(figures2017$Rank2017)

unploy2017 <- cbind(states2017,figures2017) 
unploy2017 <- unploy2017[order(unploy2017$State),]


# for 2018 (october)
page <- read_html("https://www.bls.gov/web/laus/laumstrk.htm")
states2018 <- page%>% html_nodes("tr th") %>% html_text()
states2018 <- as.data.frame(states2018)
states2018 <- tbl_df(states2018)
states2018 <- states2018[c(4:54),]
names(states2018)[1] <- "State"
states2018$State <- as.character(states2018$State)


figures2018 <- page%>% html_nodes("td span") %>% html_text()
figures2018 <- as.data.frame(figures2018)
figures2018 <- tbl_df(figures2018)

figures2018 <- figures2018[c(3:104),]
figures2018 <- as.data.frame(split(figures2018, 1:2))
figures2018 <- tbl_df(figures2018)
names(figures2018)[1] <- "Rate2018"
names(figures2018)[2] <- "Rank2018"
figures2018$Rate2018 <- as.character(figures2018$Rate2018)
figures2018$Rank2018 <- as.character(figures2018$Rank2018)
figures2018$Rate2018 <- as.numeric(figures2018$Rate2018)
figures2018$Rank2018 <- as.numeric(figures2018$Rank2018)

unploy2018 <- cbind(states2018,figures2018) 
unploy2018 <- unploy2018[order(unploy2018$State),]

# combining all the data in to one data set 
unployUS <- cbind(unploy2015,unploy2016,unploy2017,unploy2018)
unployUS <- unployUS[,-c(4,7,10)]

# we are up and running 


# combining the two datasets
comparedata <- cbind(PopulationUS,unployUS)
comparedata <- comparedata[,-6]

```


```{r Data_import_weather}

# weather data 
# sunshine 

page <- read_html("https://www.currentresults.com/Weather/US/average-annual-state-sunshine.php")

sun <- page%>% html_nodes("tr td") %>% html_text()

sun <- as.data.frame(sun)

sun <- as.data.frame(split(sun, 1:5))

sun <- tbl_df(sun)

sun <- sun[,c(1,5)]

names(sun)[1] <- "State"
names(sun)[2] <- "Clear_days"

sun$State <- as.character(sun$State)
sun$Clear_days <- as.character(sun$Clear_days)
sun$Clear_days <- as.numeric(sun$Clear_days)

sun <- sun[order(sun$State),]

# finished 



# temperature 
page <- read_html("https://www.currentresults.com/Weather/US/average-annual-state-temperatures.php")

temp <- page%>% html_nodes("tr td") %>% html_text()

temp <- as.data.frame(temp)

temp <- as.data.frame(split(temp, 1:4))

temp <- tbl_df(temp)

temp <- temp[,c(1,3)]

names(temp)[1] <- "State"
names(temp)[2] <- "TempC"

temp$State <- as.character(temp$State)
temp$TempC <- as.character(temp$TempC)
temp$TempC <- as.numeric(temp$TempC)

temp <- temp[order(temp$State),]

# finished 

page <- read_html("https://www.currentresults.com/Weather/US/average-annual-state-precipitation.php")

prec <- page%>% html_nodes("tr td") %>% html_text()

prec <- as.data.frame(prec)

prec <- as.data.frame(split(prec, 1:4))

prec <- tbl_df(prec)

prec <- prec[,c(1,3)]

names(prec)[1] <- "State"
names(prec)[2] <- "PrecipitationMM"

prec$State <- as.character(prec$State)
prec$PrecipitationMM <- as.character(prec$PrecipitationMM)
prec$PrecipitationMM <- as.numeric(prec$PrecipitationMM)

prec <- prec[order(prec$State),]

# finished 

weather <- cbind(sun,temp,prec)
weather <- weather[,c(1,2,4,6)]
# DC missing so must NA manually 
DC <-  data.frame(State = "District of Columbia", Clear_days = NA, TempC = NA, PrecipitationMM = NA)
weather = rbind(weather,DC)
weather <- weather[order(weather$State),]
# weather data is finished 

#########################
# Adding it to "comparedata"

comparedata <- cbind(comparedata,weather)
comparedata <- comparedata[,-14]

  
```


```{r Data_import_income}
# Data on medianincome from api
getdata <- fromJSON("https://api.datausa.io/api/?sort=desc&show=geo&required=income&sumlevel=state&year=all&where=geo%3A%5E04000US")

#Getting data out of list
income <- getdata[["data"]]

#Labeling data 
colnames(income)[1:3] <- c("year","state", "median_income")

#Exporting data to a csv file to avoid problems with atomic vectors
write.csv(income, file = "MyData.csv")

#Importing the csv
income <- read_csv("mydata.csv", col_types = cols(X1 = col_skip()))


#Recoding variables
income <- income %>% mutate(state = case_when(
                                              state == "04000US01" ~ "Alabama",
                                              state == "04000US02" ~ "Alaska",
                                              state == "04000US04" ~ "Arizona",
                                              state == "04000US05" ~ "Arkansas",
                                              state == "04000US06" ~ "California",
                                              state == "04000US08" ~ "Colorado",
                                              state == "04000US09" ~ "Connecticut",
                                              state == "04000US10" ~ "Delaware",
                                              state == "04000US11" ~ "District of Columbia",
                                              state == "04000US12" ~ "Florida",
                                              state == "04000US13" ~ "Georgia",
                                              state == "04000US15" ~ "Hawaii",
                                              state == "04000US16" ~ "Idaho",
                                              state == "04000US17" ~ "Illinois",
                                              state == "04000US18" ~ "Indiana",
                                              state == "04000US19" ~ "Iowa",
                                              state == "04000US20" ~ "Kansas",
                                              state == "04000US21" ~ "Kentucky",
                                              state == "04000US22" ~ "Louisiana",
                                              state == "04000US23" ~ "Maine",
                                              state == "04000US24" ~ "Maryland",
                                              state == "04000US25" ~ "Massachusetts",
                                              state == "04000US26" ~ "Michigan",
                                              state == "04000US27" ~ "Minnesota",
                                              state == "04000US28" ~ "Mississippi",
                                              state == "04000US29" ~ "Missouri",
                                              state == "04000US30" ~ "Montana",
                                              state == "04000US31" ~ "Nebraska",
                                              state == "04000US32" ~ "Nevada",
                                              state == "04000US33" ~ "New Hampshire",
                                              state == "04000US34" ~ "New Jersey",
                                              state == "04000US35" ~ "New Mexico",
                                              state == "04000US36" ~ "New York",
                                              state == "04000US37" ~ "North Carolina",
                                              state == "04000US38" ~ "North Dakota",
                                              state == "04000US39" ~ "North Ohio",
                                              state == "04000US40" ~ "Oklahoma", 
                                              state == "04000US41" ~ "Oregon", 
                                              state == "04000US42" ~ "Pennsylvania",
                                              state == "04000US44" ~ "Rhode Island",
                                              state == "04000US45" ~ "South Carolina",
                                              state == "04000US46" ~ "South Dakota",
                                              state == "04000US47" ~ "Tennessee",
                                              state == "04000US48" ~ "Texas",
                                              state == "04000US49" ~ "Utah",
                                              state == "04000US50" ~ "Vermont",
                                              state == "04000US51" ~ "Virginia",
                                              state == "04000US53" ~ "Washington",
                                              state == "04000US54" ~ "West Virginia",
                                              state == "04000US55" ~ "Wisconsin",
                                              state == "04000US56" ~ "Wyoming",
                                              state == "04000US72" ~ "Puerto Rico"))

  
income2015 <-  income %>% filter(year == 2015)
income2015 <- income2015[,c(2,3)]
income2015 <- income2015[-40,]
names(income2015)[1]  <- "State"
names(income2015)[2]  <- "Median_income15"
income2015 <- income2015[order(income2015$State),]


income2016 <-  income %>% filter(year == 2016)
income2016 <- income2016[,c(2,3)]
income2016 <- income2016[-52,]
names(income2016)[1]  <- "State"
names(income2016)[2]  <- "Median_income16"
income2016 <- income2016[order(income2016$State),]


incomeUS <- cbind(income2015,income2016)
incomeUS <- incomeUS[,c(1,2,4)]
```


```{r Data_import_maps}
# setting digits to 9 for precise latitude longitude data 
#options(digits=9)

# setting what page to scrape HTML data from 
page <- read_html("https://inkplant.com/code/state-latitudes-longitudes")

# Naming the dataset and collecting the html node (data table) from our page as html text
statesmap <- page%>% html_nodes("tr td") %>% html_text()

# making it a dataframe of 1 colum and 156 observations 
statesmap <- as.data.frame(statesmap)

# dividing it to three colums spliting for three observations a time into one of the three colums 
statesmap <- as.data.frame(split(statesmap, 1:3))

# making every colum to a character colum so it is easy to work with 
statesmap$statesmap <- as.character(statesmap$statesmap)
statesmap$statesmap.1 <- as.character(statesmap$statesmap.1)
statesmap$statesmap.2 <- as.character(statesmap$statesmap.2)

# Using dplyr to convert it from 'data.frame' to ???tbl_df???, ???tbl??? and 'data.frame'
statesmap <- tbl_df(statesmap)

# making the first row the names of the variable then removing the row afterwards 
colnames(statesmap) <- statesmap[1,]
statesmap <- statesmap[-1, ,drop=FALSE]

# making the longitude and latitude data numeric
statesmap$Latitude <- as.numeric(statesmap$Latitude)
statesmap$Longitude <- as.numeric(statesmap$Longitude)

# ordering alfabetically just in case
statesmap <- statesmap[order(statesmap$State),]

```


```{r Compare_data_set}
# Last cbind to make the compare date complete 
comparedata <- cbind(comparedata, incomeUS, statesmap)
comparedata <- comparedata[,-c(17,20)]

```


```{r Data_import_drugOD_state}

# average of drug deaths compared to all deaths in the US. 
# 2015 
totaldeath15 <-  drug_set %>% filter(Indicator =='Number of Deaths') %>% filter(Year =='2015') 
totaldeath15 <- totaldeath15[,c(1,6)]
totaldeath15 <- totaldeath15[1:636,]
colnames(totaldeath15) <- c("State", "Deaths")
totaldeath15 <- aggregate(Deaths~State, totaldeath15 , sum)
totaldeath15 <- totaldeath15[-c(45,53),]
totaldeath15 <- tbl_df(totaldeath15)
totaldeath15 <- totaldeath15[order(totaldeath15$State),]



# for 2016 
totaldeath16 <-  drug_set %>% filter(Indicator =='Number of Deaths') %>% filter(Year =='2016') 
totaldeath16 <- totaldeath16[,c(1,6)]
totaldeath16 <- totaldeath16[1:636,]
colnames(totaldeath16) <- c("State", "Deaths")
totaldeath16 <- aggregate(Deaths~State, totaldeath16 , sum)
totaldeath16 <- totaldeath16[-c(45,53),]
totaldeath16 <- tbl_df(totaldeath16)
totaldeath16 <- totaldeath16[order(totaldeath16$State),]



# for 2017 
totaldeath17 <-  drug_set %>% filter(Indicator =='Number of Deaths') %>% filter(Year =='2017') 
totaldeath17 <- totaldeath17[,c(1,6)]
totaldeath17 <- totaldeath17[1:636,]
colnames(totaldeath17) <- c("State", "Deaths")
totaldeath17 <- aggregate(Deaths~State, totaldeath17 , sum)
totaldeath17 <- totaldeath17[-c(45,53),]
totaldeath17 <- tbl_df(totaldeath17)
totaldeath17 <- totaldeath17[order(totaldeath17$State),]





# Drug overdoses pr state for 2015 
drug_od_state15 <-  drug_set %>% filter(Indicator =='Number of Drug Overdose Deaths') %>% filter(Year =='2015') 
drug_od_state15 <- drug_od_state15[,c(1,6)]
drug_od_state15 <- drug_od_state15[1:636,]
colnames(drug_od_state15) <- c("State", "Drug_od15")
drug_od_state15 <- aggregate(Drug_od15~State, drug_od_state15 , sum)
drug_od_state15 <- drug_od_state15[-c(45,53),]
drug_od_state15 <- tbl_df(drug_od_state15)
drug_od_state15 <- drug_od_state15[order(drug_od_state15$State),]



# Drug overdoses pr state for 2016 
drug_od_state16 <-  drug_set %>% filter(Indicator =='Number of Drug Overdose Deaths') %>% filter(Year =='2016')
drug_od_state16 <- drug_od_state16[,c(1,6)]
drug_od_state16 <- drug_od_state16[1:636,]
colnames(drug_od_state16) <- c("State", "Drug_od16")
drug_od_state16 <- aggregate(Drug_od16~State, drug_od_state16 , sum)
drug_od_state16 <- drug_od_state16[-c(45,53),]
drug_od_state16 <- tbl_df(drug_od_state16)
drug_od_state16 <- drug_od_state16[order(drug_od_state16$State),]




# Drug overdoses pr state for 2017 
drug_od_state17 <-  drug_set %>% filter(Indicator =='Number of Drug Overdose Deaths') %>% filter(Year =='2017')
#f <- filter(drug_od_state17, State_name == "Alaska")
drug_od_state17 <- drug_od_state17[,c(1,6)]
drug_od_state17 <- drug_od_state17[1:636,]
colnames(drug_od_state17) <- c("State", "Drug_od17")
drug_od_state17 <- aggregate(Drug_od17~State, drug_od_state17 , sum)
drug_od_state17 <- drug_od_state17[-c(45,53),]
drug_od_state17 <- tbl_df(drug_od_state17)
drug_od_state17 <- drug_od_state17[order(drug_od_state17$State),]


comparedata <- cbind(comparedata, drug_od_state15, drug_od_state16, drug_od_state17)
comparedata <- comparedata[,-c(21,23,25)]
# Now we have everything we need for comparison on drug overdoses pr state!

df1 <- cbind(totaldeath15,drug_od_state15)
df1$percent <- (df1$Drug_od15/df1$Deaths)*100

# mean(df1$percent) # 1.9 % of all deaths in average in the us was drug related in 2015




df2 <- cbind(totaldeath16,drug_od_state16)
df2$percent <- (df2$Drug_od16/df2$Deaths)*100

# mean(df2$percent) # 2.2 % of all deaths in average in the us was drug related in 2016




df3 <- cbind(totaldeath17,drug_od_state17)
df3$percent <- (df3$Drug_od17/df3$Deaths)*100

# mean(df3$percent) # 2.45 % of all deaths in average in the us was drug related in 2017



```



```{r Data_od_pr_state}

odcomp <- cbind(comparedata$State, 
                comparedata$Drug_od15/comparedata$Population2015,
                comparedata$Drug_od16/comparedata$Population2016,
                comparedata$Drug_od17/comparedata$Population2017)

colnames(odcomp) <- c("State","OD15_relation","OD16_relation","OD17_relation")
odcomp <- tbl_df(odcomp)
odcomp$OD15_relation <- as.numeric(odcomp$OD15_relation)
odcomp$OD16_relation <- as.numeric(odcomp$OD16_relation)
odcomp$OD17_relation <- as.numeric(odcomp$OD17_relation)


odcomp$OD15_Deathspr10000 <- odcomp$OD15_relation*10000
odcomp$OD16_Deathspr10000 <- odcomp$OD16_relation*10000
odcomp$OD17_Deathspr10000 <- odcomp$OD17_relation*10000


# # for alabama 
# 8818/4858979 # od/pop
# 10000*0.00181478455 # 18 number of deaths for 10 000 people in alabama 
 
 
# # for florida 
# 65444/20271272
# 10000*0.00322841112 # 32 number of deaths for 10 000 people in florida 
 

# # california 
# 56001/39144818
# 10000*0.00143061082 # 14 number of deaths for 10 000 people in california 

```


```{r Plot_data}
# Mulig beste fremstilling av Omsetning, kostnader og driftsresultat?
odcomp1 <- odcomp
odcomp1 <- odcomp1[,c(1,5,6,7)]
colnames(odcomp1) <- c("State","2015","2016","2017")
odcomp1$State <- as.factor(odcomp1$State) # setting as factor so could use fun melt 
odcomp2 <- melt(odcomp1) # melting with years as desiding variable 
names(odcomp2)[2] <- "Year"
odcomp2$State <- as.character(odcomp2$State)

northeast <-  odcomp2 %>% filter(State %in% c("Connecticut", "Maine", "Massachusetts", "New Hampshire", "Rhode Island", "Vermont", "New Jersey", "New York" ,"Pennsylvania"))

midwest <-  odcomp2 %>% filter(State %in% c("Illinois", "Indiana", "Michigan", "Ohio", "Wisconsin", "Iowa", "Kansas", "Minnesota", "Missouri", "Nebraska", "North Dakota", "South Dakota"))


south <-  odcomp2 %>% filter(State %in% c("Delaware", "Florida", "Georgia", "Maryland", "North Carolina", "South Carolina", "Virginia", "District of Columbia", "West Virginia", "Alabama", "Kentucky", "Mississippi", "Tennessee" ,"Arkansas", "Louisiana", "Oklahoma","Texas"))


west <-  odcomp2 %>% filter(State %in% c("Arizona", "Colorado", "Idaho", "Montana", "Nevada", "New Mexico", "Utah", "Wyoming", "Alaska", "California", "Hawaii", "Oregon", "Washington"))


# Region 1: Northeast
# Division 1: New England (Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, and Vermont)
# Division 2: Mid-Atlantic (New Jersey, New York, and Pennsylvania)

# Region 2: Midwest (Prior to June 1984, the Midwest Region was designated as the North Central Region.)[6]
# Division 3: East North Central (Illinois, Indiana, Michigan, Ohio, and Wisconsin)
# Division 4: West North Central (Iowa, Kansas, Minnesota, Missouri, Nebraska, North Dakota, and South Dakota)

# Region 3: South
# Division 5: South Atlantic (Delaware, Florida, Georgia, Maryland, North Carolina, South Carolina, Virginia, District of Columbia, and West Virginia)
# Division 6: East South Central (Alabama, Kentucky, Mississippi, and Tennessee)
# Division 7: West South Central (Arkansas, Louisiana, Oklahoma, and Texas)

# Region 4: West
# Division 8: Mountain (Arizona, Colorado, Idaho, Montana, Nevada, New Mexico, Utah, and Wyoming)
# Division 9: Pacific (Alaska, California, Hawaii, Oregon, and Washington)
```

# Drug related deaths in the US - A case study 

## Overview and Motivation:
Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.


## Related Work: Anything that inspired you, such as a paper, a web site, or something we discussed in class:
Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.


## Summary of study
Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.


# Let´s get dirty & take a look at the total number of drug deaths per state scaled for 10 000 inhabitants.
## Northeast 
```{r northeast_plot}
ggplot(northeast, aes(x = State, y = value, fill = Year)) +
geom_bar(stat="identity", width=.7, position = "dodge") + 
  coord_flip()+
  theme_classic() +
  scale_fill_brewer(palette="PuBu")+
  labs(
        title = "OD-deaths pr 10 000 inhabitants",
        x = "State",
        y = "Deaths") 
```


## Midwest
```{r midwest_plot}
ggplot(midwest, aes(x = State, y = value, fill = Year)) +
geom_bar(stat="identity", width=.7, position = "dodge") + 
  coord_flip()+
  theme_classic() +
  scale_fill_brewer(palette="BrBG")+
  labs(
        title = "OD-deaths pr 10 000 inhabitants",
        x = "State",
        y = "Deaths") 
```


## South 
```{r south_plot}
ggplot(south, aes(x = State, y = value, fill = Year)) +
geom_bar(stat="identity", width=.7, position = "dodge") + 
  coord_flip()+
  scale_fill_brewer(palette="YlOrRd")+
  theme_classic() +
  labs(
        title = "OD-deaths pr 10 000 inhabitants",
        x = "State",
        y = "Deaths") 
```


## West
```{r west_plot}
ggplot(west, aes(x = State, y = value, fill = Year)) +
geom_bar(stat="identity", width=.7, position = "dodge") + 
  coord_flip()+
  scale_fill_brewer(palette="PuRd")+
  theme_classic() +
  labs(
        title = "OD-deaths pr 10 000 inhabitants",
        x = "State",
        y = "Deaths")

```



## Compared to one another 2016

```{r}
ggplot() +
  geom_bar(stat = "identity", data = odcomp, aes (x = State, y = OD16_Deathspr10000, fill = State)) +
  coord_flip()+
  guides(fill=FALSE)+
  theme_classic() + 
  #scale_x_discrete(expand=c(0,0)) +
  #scale_y_continuous(expand=c(0,0)) +
  #scale_x_continuous(breaks = driftres$year) +
  labs(
        title = "OD deaths pr 10 000 inhabitants 2016",
        x = "State",
        y = "Deaths")
```


```{r key_numbers_for_text}
# Key numbers ods. 
m15 <- mean(drug_od_state15$Drug_od15) # gjennomsnittlig døde av overdose pr stat 2015
m16 <- mean(drug_od_state16$Drug_od16) # gjennomsnittlig døde av overdose pr stat 2016
m17 <- mean(drug_od_state17$Drug_od17) # gjennomsnittlig døde av overdose pr stat 2017
tot15 <- sum(drug_od_state15$Drug_od15) # totalt antall døde av overdose pr stat 2015
tot16 <- sum(drug_od_state16$Drug_od16) # totalt antall døde av overdose pr stat 2016
tot17 <- sum(drug_od_state17$Drug_od17) # totalt antall døde av overdose pr stat 2017



# (Present-past)/past * 100 = percentage change
percha16 <- ((m16-m15)/m15)*100 # prosent endring fra 2015-2016 overdoser usa 
percha17 <- ((m17-m16)/m16)*100 # prosent endring fra 2016-2017 overdoser usa 
perchatot <- ((m17-m15)/m15)*100 # prosent endring fra 2015-2017 overdoser usa 


```

This is some serious numbers. The total average drug deaths per state for 2015 is 11 585 and worse, it increased to 15 856 in 2017. This is an increase of `r round(perchatot,2)`% from 2015 to 2017, implefying that it is a serious problem in the us. The total number of deaths by drugs was 590 825 in 2015, 682 084 in 2016 and 808 661 in 2017. This equals a total of 2 081 570 people just for the three years this case study is studying. That´s the same as the total population of Slovenia to put things in perspective. Wiped out over three years.

## But how many drug deaths do we find compared to all deaths?
A small percentage:
1.9 % of all deaths in average in the us was drug related in 2015
2.2 % of all deaths in average in the us was drug related in 2016
2.45 % of all deaths in average in the us was drug related in 2017


```{r table_of_od}
options(digits=2)

# Od rate table with worst states 2017
odcomphigh <- odcomp[with(odcomp,order(-OD16_Deathspr10000)),]

odcomphigh <- odcomphigh[1:10,]

odcomphigh <- odcomphigh[,-c(2,3,4,5,7)]
odcomphigh$Rank <- c(1:10)
names(odcomphigh)[2] <- "Deaths pr 10000 inhabitants"
#kable(odcomphigh, format = "html", caption = "The 10 states with the highest O.D-rate in 2016")


# lets compare to the states with lowest income 
inclow <- income2016[with(income2016,order(-Median_income16)),]

inclow <- inclow[42:51,] 
inclow$Rank <- c(42:51)

names(inclow)[2] <- "Median household income 2016"
inclow <-inclow[seq(dim(inclow)[1],1),]
#kable(inclow, format = "html", caption = "The 10 states with lowest median household income in 2016")



# Od rate Table with best states 2016 
odcomplow <- odcomp[with(odcomp,order(-OD16_Deathspr10000)),]

odcomplow <- odcomplow[42:51,]

odcomplow <- odcomplow[,-c(2,3,4,5,7)]

odcomplow <- odcomplow[seq(dim(odcomplow)[1],1),]
odcomplow$Rank <- c(1:10)
names(odcomplow)[2] <- "Deaths pr 10000 inhabitants"

#kable(odcomplow, format = "html", caption = "The 10 states with the lowest O.D-rate in 2016")


# Lets take a look at income and compare 

inchigh <- income2016[with(income2016,order(-Median_income16)),]

inchigh <- inchigh[1:10,]  
inchigh$Rank <- c(1:10)

names(inchigh)[2] <- "Median household income 2016"
#kable(inchigh, format = "html", caption = "The 10 states with highest median household income in 2016")

# What about unemployment rate?

ployhigh <- unploy2016[with(unploy2016,order(-Rate2016)),]
names(ployhigh)[3] <- "Rank"
ploylow <-  ployhigh[42:51,] 
ployhigh <- ployhigh[1:10,] 
names(ploylow)[2] <- "The unemployment rate in percent of states labor force 2016"
names(ployhigh)[2] <- "The unemployment rate in percent of states labor force 2016"
ploylow <-  tbl_df(ploylow)
ployhigh <- tbl_df(ployhigh)
ploylow <- ploylow[seq(dim(ploylow)[1],1),]

row.names(ploylow) <- NULL
row.names(ployhigh) <- NULL


# weather with regards to temperature? 

weathergood <- weather[with(weather,order(-TempC)),]
weathergood <- weathergood[-51,]
weathergood <- weathergood[,c(1,3)]
weatherbad <- weathergood[41:50,]
weathergood <- weathergood[1:10,]
weathergood$Rank <- c(1:10)
weathergood <-  tbl_df(weathergood)
weatherbad <- tbl_df(weatherbad)
weatherbad <- weatherbad[seq(dim(weatherbad)[1],1),]
weatherbad$Rank <- c(1:10)
row.names(weathergood) <- NULL
row.names(weatherbad) <- NULL

#kable(ploylow, format = "html", caption = "The 10 states with lowest unemployment in 2016")
#kable(ployhigh, format = "html", caption = "The 10 states with highest unemployment in 2016")

```

## Low income and high unemployment will result in high overdose rate?
Our assupmption is that low income and high unemployment equals high od-rate. So we take a look at the top 10 states of high od-rate, lowest income and highest unemployment. 
```{r}
knitr::kable(list(odcomphigh, inclow,ployhigh))

```
As we can se this is not allways the case. West Wirginia stands out and is represented badly in all three categories. The people working in DC make good money, but both unemployment and od-rate are high. Kentucky is represented in the table for low income. Maryland is the states with highest income the last couple of years by a solid margin, and is the 9th worst place for od in the country. Othervise the similarities was not as strong as expected.

## But high income and low unemployment would equal low od-rate right?
Not for Maryland thats for sure. 
```{r}
knitr::kable(list(odcomplow, inchigh,ploylow))

```

## What about the states with High(good) and low(bad) temperatures?

```{r}
knitr::kable(list(weathergood, weatherbad))
```

blablabla

```{r correlation}

# jo flere folk som bor i en stat
cor(comparedata$Drug_od16,comparedata$Population2016)

# jo høyere arbeidsledighet 
cor(comparedata$Drug_od16,comparedata$Rate2016)


# jo høyere inntekt 
cor(comparedata$Drug_od16,comparedata$Median_income16)

comparedata2 <- comparedata
comparedata2 <- comparedata2[-9,]

# jo høyere temperatur 
cor(comparedata2$Drug_od16,comparedata2$TempC)

```


  


```{r Monthly}
#Monthly average overdose deaths for every year and for all drugs in the dataset

#All type of drug deaths in 2015
NODOD_2015 <-  drug_set %>% filter(Indicator =='Number of Drug Overdose Deaths') %>% filter(Year =='2015')
NODOD_2015 <- NODOD_2015[1:636,] # REMOVING DUPLICATES
#All type of drug deaths in 2016
NODOD_2016 <-  drug_set %>% filter(Indicator =='Number of Drug Overdose Deaths') %>% filter(Year =='2016')
NODOD_2016 <- NODOD_2016[1:636,] # REMOVING DUPLICATES
#All type of drug deaths in 2017
NODOD_2017 <-  drug_set %>% filter(Indicator =='Number of Drug Overdose Deaths') %>% filter(Year =='2017')
NODOD_2017 <- NODOD_2017[1:636,] # REMOVING DUPLICATES
#All type of drug deaths in 2018
NODOD_2018 <-  drug_set %>% filter(Indicator =='Number of Drug Overdose Deaths') %>% filter(Year =='2018')
NODOD_2018 <- NODOD_2018[1:212,] # REMOVING DUPLICATES



#Average deaths related to all drugs by month for 2015
avg_monthly_2015 <- aggregate(Deaths ~ Month, NODOD_2015, mean) 
#Average deaths related to all drugs by month for 2016
avg_monthly_2016 <- aggregate(Deaths ~ Month, NODOD_2016, mean)
#Average deaths related to all drugs by month for 2017
avg_monthly_2017 <- aggregate(Deaths ~ Month, NODOD_2017, mean)
#Average deaths related to all drugs by month for 2018
avg_monthly_2018 <- aggregate(Deaths ~ Month, NODOD_2018, mean)

#Putting the months for 2015 in the right order
avg_monthly_2015 <- avg_monthly_2015[c(5,4,8,1,9,7,6,2,12,11,10,3),]
#Putting the months for 2016 in the right order
avg_monthly_2016 <- avg_monthly_2016[c(5,4,8,1,9,7,6,2,12,11,10,3),]
#Putting the months for 2017 in the right order
avg_monthly_2017 <- avg_monthly_2017[c(5,4,8,1,9,7,6,2,12,11,10,3),]
#Putting the months for 2018 in the right order (ONLY 4 MONTHS FOR THIS SET)
avg_monthly_2018 <- avg_monthly_2018[c(3,2,4,1),]


#Making a function that converts months to numbers
month_to_number <- function(dataset){
dataset$Month[dataset$Month =="January"] <- 1
dataset$Month[dataset$Month =="February"] <- 2
dataset$Month[dataset$Month =="March"] <- 3
dataset$Month[dataset$Month =="April"] <- 4
dataset$Month[dataset$Month =="May"] <- 5
dataset$Month[dataset$Month =="June"] <- 6
dataset$Month[dataset$Month =="July"] <- 7
dataset$Month[dataset$Month =="August"] <- 8
dataset$Month[dataset$Month =="September"] <- 9
dataset$Month[dataset$Month =="October"] <- 10
dataset$Month[dataset$Month =="November"] <- 11
dataset$Month[dataset$Month =="December"] <- 12
return(dataset)
}

#Using the function to make names of them months to numbers
avg_monthly_2015 <- month_to_number(avg_monthly_2015)
avg_monthly_2016 <- month_to_number(avg_monthly_2016)
avg_monthly_2017 <- month_to_number(avg_monthly_2017)
avg_monthly_2018 <- month_to_number(avg_monthly_2018)

#Making a function that does a work around to get the months in chronological order
workaround <- function(dataset,csv_name){
write.csv(dataset, file = "csv_name") 
dataset <- read_csv("csv_name", col_types = cols(X1 = col_skip()))
}


#Using the function for every year so the months are in chronological order
avg_monthly_2015 <- workaround(avg_monthly_2015,avg_monthly_2015.CSV)
avg_monthly_2016 <- workaround(avg_monthly_2016,avg_monthly_2016.CSV)
avg_monthly_2017 <- workaround(avg_monthly_2017,avg_monthly_2017.CSV)
avg_monthly_2018 <- workaround(avg_monthly_2018,avg_monthly_2018.CSV)

#Making a plot that contains all the years
ggplot() +
    geom_line(data = avg_monthly_2015, aes(x = Month, y =Deaths,group = 1), colour = "red" ) +   #2015
    geom_line(data = avg_monthly_2016, aes(x = Month, y =Deaths,group = 1), colour = "blue") +    #2016
  geom_line(data = avg_monthly_2017, aes(x = Month, y =Deaths,group = 1), colour = "Orange") +  #2017
    geom_line(data = avg_monthly_2018, aes(x = Month, y =Deaths,group = 1), colour = "green") +  #2018
    xlab("Month") + ylab("Deaths")  +
  scale_x_continuous(breaks = avg_monthly_2015$Month) +
  theme_classic()

```



```{r Deaths_compared_to_overdoses}
#Comparing the average number of deaths to the average number of drug related deaths

#Using data from the last chunk (MONTHLY) to create a vector for overdose means
mean_overdoses <- c(mean(avg_monthly_2015$Deaths),mean(avg_monthly_2016$Deaths),mean(avg_monthly_2017$Deaths),mean(avg_monthly_2018$Deaths))


#All types of deaths in 2015
NOD_2015 <-  drug_set %>% filter(Indicator =='Number of Deaths') %>% filter(Year =='2015')
NOD_2015 <- NOD_2015[1:636,] # REMOVING DUPLICATES
#All types of deaths in 2016
NOD_2016 <-  drug_set %>% filter(Indicator =='Number of Deaths') %>% filter(Year =='2016')
NOD_2016 <- NOD_2016[1:636,] # REMOVING DUPLICATES
#All types of deaths in 2017
NOD_2017 <-  drug_set %>% filter(Indicator =='Number of Deaths') %>% filter(Year =='2017')
NOD_2017 <- NOD_2017[1:636,] # REMOVING DUPLICATES
#All types of deaths in 2018
NOD_2018 <-  drug_set %>% filter(Indicator =='Number of Deaths') %>% filter(Year =='2018')
NOD_2018 <- NOD_2018[1:212,] # REMOVING DUPLICATES

#Average deaths by month for 2015
avg_monthly_deaths_2015 <- aggregate(Deaths ~ Month, NOD_2015, mean) 
#Average deaths by month for 2016
avg_monthly_deaths_2016 <- aggregate(Deaths ~ Month, NOD_2016, mean)
#Average deaths by month for 2016
avg_monthly_deaths_2017 <- aggregate(Deaths ~ Month, NOD_2017, mean)
#Average deaths by month for 2016
avg_monthly_deaths_2018 <- aggregate(Deaths ~ Month, NOD_2018, mean)

#making a vector the means for all deaths
mean_deaths <- c(mean(avg_monthly_deaths_2015$Deaths),mean(avg_monthly_deaths_2016$Deaths),mean(avg_monthly_deaths_2017$Deaths),mean(avg_monthly_deaths_2018$Deaths))

#Making a vector of the years
years <- c(2015,2016,2017,2018)

#Making a data frame out of the vectors
mean_overdoses <- data.frame(years,mean_overdoses)
mean_deaths <- data.frame(years,mean_deaths)




ggplot() +
    geom_line(data = mean_overdoses, aes(x = years, y =mean_overdoses, group = 1), colour = "red" ) +  xlab("Month") + ylab("Year") + theme_classic()

ggplot() +
    geom_line(data = mean_deaths, aes(x = years, y =mean_deaths, group = 1), colour = "blue" ) +  xlab("Month") + ylab("Year") +
  theme_classic()


```



```{r Graph_median_income}

#Scatter plot for median income
ggplot(data = income, aes(x=median_income, y=state, colour = state)) +
  geom_jitter() +
  theme_classic()+
  guides(fill=FALSE)+
  labs(
        title = "Scatter plot of median income",
        x = "Median income",
        y = "State") #Ignore error

```


```{r Death_by_drug_graph}

#Sorting out by the type of drugs
just_drugs <- drug_set %>%
  filter(
    Indicator != "Number of Deaths"  &
    Indicator != "Number of Drug Overdose Deaths"  &
    Indicator != "Percent with drugs specified"

)



ggplot(data=just_drugs, aes(x=Indicator , y= Deaths, fill = Indicator)) +
    coord_flip() +
    theme_minimal()+
    geom_bar(stat="identity") +
    labs(
        title = "Most lethal drug",
        x = "Deaths",
        y = "Drug")
```




```{r leaflet_popup_setup}
# Autogenerated text for the leaflet function 
# This is quite som work, but it ensures that the autogenerated text for the popup in leaflet is collected automaticaly 
# with no human errors. Every chunk of code is telling a story for the specific state and is made into data.frame of 51 characters that later are colapsed into one data.frame and the "" seperator between the characters is removed to make it into one text. 


stat <-  c(comparedata$State)
stat <- as.data.frame(stat)
stat$stat <- as.character(stat$stat)


nr1 <- " had a total number of deaths by drugs of "
nr1 <- rep(nr1, 51)
nr1 <- as.data.frame(nr1)
nr1$nr1 <- as.character(nr1$nr1)


verdi1 <- c(comparedata$Drug_od16)
verdi1 <- as.data.frame(verdi1)
verdi1$verdi1 <- as.character(verdi1$verdi1)


nr2 <- " persons in 2016. This is with a population of "
nr2 <- rep(nr2, 51)
nr2 <- as.data.frame(nr2)
nr2$nr2 <- as.character(nr2$nr2)


verdi2 <- c(comparedata$Population2016)
verdi2 <- as.data.frame(verdi2)
verdi2$verdi2 <- as.character(verdi2$verdi2)


nr3 <- " people living in the entire state. This equals to "
nr3 <- rep(nr3, 51)
nr3 <- as.data.frame(nr3)
nr3$nr3 <- as.character(nr3$nr3)


verdi3 <- c(round(odcomp$OD16_Deathspr10000,0))
verdi3 <- as.data.frame(verdi3)
verdi3$verdi3 <- as.character(verdi3$verdi3)


nr4 <- " deaths every 10 000 persons. "
nr4 <- rep(nr4, 51)
nr4 <- as.data.frame(nr4)
nr4$nr4 <- as.character(nr4$nr4)


nr5 <- "The state ranked number "
nr5 <- rep(nr5, 51)
nr5 <- as.data.frame(nr5)
nr5$nr5 <- as.character(nr5$nr5)


verdi4 <- c(comparedata$Rank2016)
verdi4 <- as.data.frame(verdi4)
verdi4$verdi4 <- as.character(verdi4$verdi4)


nr6 <- " in total of the 51 states when it came to unemployment, and had a median household income of "
nr6 <- rep(nr6, 51)
nr6 <- as.data.frame(nr6)
nr6$nr6 <- as.character(nr6$nr6)


verdi5 <- c(comparedata$Median_income16)
verdi5 <- as.data.frame(verdi5)
verdi5$verdi5 <- as.character(verdi5$verdi5)


nr7 <- " USD in 2016. "
nr7 <- rep(nr7, 51)
nr7 <- as.data.frame(nr7)
nr7$nr7 <- as.character(nr7$nr7)


#stat


nr8 <- " has an average of "
nr8 <- rep(nr8, 51)
nr8 <- as.data.frame(nr8)
nr8$nr8 <- as.character(nr8$nr8)


verdi6 <- c(comparedata$Clear_days)
verdi6 <- as.data.frame(verdi6)
verdi6$verdi6 <- as.character(verdi6$verdi6)


nr9 <- " suny days during a year, with a temperature of "
nr9 <- rep(nr9, 51)
nr9 <- as.data.frame(nr9)
nr9$nr9 <- as.character(nr9$nr9)


verdi7 <- c(comparedata$TempC)
verdi7 <- as.data.frame(verdi7)
verdi7$verdi7 <- as.character(verdi7$verdi7)


nr10 <- " degrees and "
nr10 <- rep(nr10, 51)
nr10 <- as.data.frame(nr10)
nr10$nr10 <- as.character(nr10$nr10)


verdi8 <- c(comparedata$PrecipitationMM)
verdi8 <- as.data.frame(verdi8)
verdi8$verdi8 <- as.character(verdi8$verdi8)


nr11 <- " mm downfall in average. All factors that in some way, possibly can explain the overdoses in the state."
nr11 <- rep(nr11, 51)
nr11 <- as.data.frame(nr11)
nr11$nr11 <- as.character(nr11$nr11)


# The storytelling is finished, now we collapse everything.


popupgo <- paste(stat$stat, nr1$nr1, verdi1$verdi1, nr2$nr2, verdi2$verdi2, nr3$nr3, verdi3$verdi3, nr4$nr4, nr5$nr5, verdi4$verdi4, nr6$nr6, verdi5$verdi5 ,nr7$nr7,stat$stat, nr8$nr8, verdi6$verdi6, nr9$nr9, verdi7$verdi7, nr10$nr10, verdi8$verdi8, nr11$nr11, sep ="")


```



```{r Map, echo = FALSE, message= FALSE, fig.width=8}
# The map is interactive, so feel free to zoom in and read about the specific states clicking the popup icon. 

# basic map
m <- leaflet() %>%
  addTiles() %>%  
  addMarkers(lng=c(comparedata$Longitude), lat=c(comparedata$Latitude), 
             popup = c(popupgo))

# Using a NASA picture by night in 2012 for the map for cooler apperance and to show by light pollution where the crowded areas of the nation is. 
m %>% addProviderTiles("NASAGIBS.ViirsEarthAtNight2012")

# code for other apperances:
# browseURL("https://wiki.earthdata.nasa.gov/display/GIBS/GIBS+API+for+Developers#GIBSAPIforDevelopers-TimeDimension")

# trying some other apperances 

# m %>% addProviderTiles("MtbMap")
# m %>% addProviderTiles("HikeBike.HikeBike")

# With opacity 0.5
# leaflet() %>%
#     addTiles() %>%  
#     addMarkers(lng=c(long), lat=c(lat), 
#              popup = c(namestate)) %>% 
#     addProviderTiles("NASAGIBS.ModisTerraTrueColorCR",
#                         options = providerTileOptions(time = "2015-08-30", opacity = 0.5))

# With opacity 1. now a satelitte image 
# leaflet() %>%
#     addTiles() %>%  
#     addMarkers(lng=c(long), lat=c(lat), 
#              popup = c(namestate)) %>% 
#     addProviderTiles("NASAGIBS.ModisTerraTrueColorCR",
#                         options = providerTileOptions(time = "2015-08-30", opacity = 1))

# 1. december this year  
# leaflet() %>%
#     addTiles() %>%  
#     addMarkers(lng=c(long), lat=c(lat), 
#              popup = c(namestate)) %>% 
#     addProviderTiles("NASAGIBS.ModisTerraTrueColorCR",
#                         options = providerTileOptions(time = "2018-12-01", opacity = 0.7))
```

## What will a linear regression model say about OD dependent on income, weather and unemployment?

```{r linear_regression}
comparedata <- cbind(comparedata,odcomp)


fit <- lm(OD16_relation~Median_income16+PrecipitationMM+Clear_days+Rate2016, data = comparedata)


summary(fit)

```




<!--Jumbotron -->



<div class="jumbotron jumbotron-fluid" id="background_div">
<h1 class = "text-center" >Drug related deaths in Conneticut</h1>




<!-- Introduction text -->
<div class = "container" id  = "introduction">
<hr style ="margin-bottom:10%;" />

  <h2 class = "text-center"> Introduction </h2>
  <p class = "text-center"> In this casestudy we're going to look at drug related death in Conneticut ipsoms lorums ripsbusker og andre buskvekster ipsoms lorums ripsbusker og andre buskvekster ipsoms lorums ripsbusker og andre buskvekster ipsoms lorums ripsbusker og andre buskvekster  </p> 
  
<hr style = margin-top:10% />




<!--Numbers -->
<div id="numbers">   
<div class="container-fluid" id="numbers_container">   

<div class="card">
<center>


</center>

<div class="card-body">
<p class="card-text text-center">Drug related use up by going to look at drug related death in Conneticut ipsoms lorums ripsbusker og andre buskvekster ipsoms lorums ripsbuske </p>
</div>
</div>




</div>
</div>



<!--Maps -->
<div class = "container" id  = "maps">
  <h2 class = "text-center"> Map </h2>


<center>






<!--Statistics -->


<div id ="stat">
<h2 class = "text-center"> Statistics </h2>

<div class="container-fluid" id="stat_container">   

<div class="col-md-6" id = "graph1">


</div>


<div class="col-md-6" id = "textgraph">
<p> ipsoms lorums ripsbusker og andre buskvekster ipsoms lorums ripsbusker og andre buskvekster ipsoms lorums ripsbusker og andre buskvekster </p>
</div>


</div>
</div>









</div>


  






